{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting Fraud - An Exploratory Data Analysis\n",
    "\n",
    "A methodical EDA (exploratory data analysis) is comprised of four steps.   \n",
    "\n",
    "  - The first of these steps involves loading the data into memory and storing it in a dataframe.  When a dataset does not fit into memory there are alternative methods of doing this - though I am unsure of what those are.\n",
    "  -  In step 12 we will make the data set a \"tidy data\" set by following the guidelines established by Hadley Wickham.\n",
    " http://vita.had.co.nz/papers/tidy-data.html\n",
    "  - Step three will use descriptive statistics and exploratory visualizations to understand the data at a macro level.\n",
    "  - In step four we will aggregate the data and explore the group properties in a much more detailed manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "# Importing pandas 0.18.1\n",
    "# Importing numpy 1.12.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = (12, 8)\n",
    "matplotlib.pyplot.style.use('ggplot')\n",
    "pd.set_option('max.rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matplotlib.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1:  Loading and storing data set into a data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "# importing preprocess to load 'train' dataset\n",
    "# making dataframe df from 'train' dataset\n",
    "# completes step 1 of a methodical EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2:  Making a tidy data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.shape\n",
    "# Curious as to the size of the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()\n",
    "# curious as to the content of the data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why look at the head of the data set?\n",
    "\n",
    "I chose to begin step two of my EDA, tidying up the data set, by looking at the head of the data frame.  In doing this I can take a look at my column headers as well as the first 5 results where I am looking for the presence of the 3 indicators of a tidy data set:\n",
    "- Each variable forms a column\n",
    "- Each observation forms a row\n",
    "- Each type of observational unit forms a table\n",
    "\n",
    "Though not all of these are going to be appparent with only 5 observations listed, we can capture any of the obvious ones and correct them right away.\n",
    "\n",
    "According to Hadley, the 5 most frequent causes of messy data are as follows:\n",
    "- Column headers are values and not variable names\n",
    "- Mulitple variables are stored in one column\n",
    "- Variables are stored in both rows and colummns\n",
    "- Observational units types of varying kinds are stored in the same table\n",
    "- Multiple instances of a single observational type is found in numerous tables\n",
    "\n",
    "At the on set alll of these stipulations seems to be in order.  I do however take issue with the ordering of the columns.  Fixed variables should come first (left-most) followed by the measured variables.  Currently, all we have are fixed variables and the flow of the columns makes sense to me with the exception of the 'id' column.  It is my belief that this is a unique identifier for each transaction and as such it makes more sense to me that this column be moved to the far left side of the data frame.  I've also corrected the column header 'oldbalanceOrg' to 'oldbalanceOrig' thinking that the typo ought to be corrected.\n",
    "\n",
    "As the analysis continues to deepen I will continue to look for additional manners to tidy up my data set where it is warranted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df[['id', 'step', 'type', 'amount', 'nameOrig', 'oldbalanceOrg',\n",
    "         'newbalanceOrig', 'nameDest', 'oldbalanceDest', 'newbalanceDest',\n",
    "         'isFraud']]\n",
    "df.head()\n",
    "# moving 'id' column to the left end of df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.rename(columns={'oldbalanceOrg': 'oldbalanceOrig'})\n",
    "# correcting 'oldbalanceOrig' column header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()\n",
    "# confirming my changes\n",
    "# completes step 2 of a methodical EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3:  Using descriptive statistics and visualizations to begin forming an understanding of the data set - macro level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What can we learn from our tabular analysis?\n",
    "By looking at the below tables we can learn from our data the following:\n",
    "- There are 445,383 observations none of which have null values\n",
    "- 576 transactions were fraudulant (276 cash_out & 300 transfer)\n",
    "- There are 5 different transaction types for us to take into account.  The msot frequest of these transaction types is the Cash_Out type.\n",
    "- Out of the 445,383 transactions we have 445,338 unique customers originating the transaction.  This means we have 45 repeat originators.  However, of these repeat originators none appear more than twice.\n",
    "- The mean transaction amount was 178,918 with the largest transaction being 60,642,000.\n",
    "- 50% of origin account new balances are 0, indicating they were drained, be it on purpose or by fraud\n",
    "- 69% (174,616) of the origin accounts having new balances of 0 ened up that way through Cash_Out and Transfer transaction types\n",
    "- 88% (150,954) of the destination accounts having new balances of 0 ended up that way through Payment transaction types\n",
    "- These same accounts have old and new balances equal to each other indicating to me they may be acting like pass through accounts.\n",
    "- The average transfer amount was 903,518.\n",
    "- I prefer tables when analyzing data despite most peoples preference for graphs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()\n",
    "# no need for imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "py.init_notebook_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from plotly import __version__\n",
    "print(__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.info()\n",
    "# getting concise summary\n",
    "# dtypes make sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.describe(include='all')\n",
    "# Getting summary statistics\n",
    "# including non-integer d-types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.crosstab(df.type, df.isFraud == 1)\n",
    "# Looking at transaction tyoes for fraudulent transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.crosstab(df.type, df.newbalanceOrig == 0.0)\n",
    "# '''Looking at post transfer balances equal to $0\n",
    "# of orgin accounts by transaction type'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.crosstab(df.type, df.newbalanceDest == 0.0)\n",
    "# '''Looking at post transfer balances equal to $0\n",
    "# of destination accounts by transaction type'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.crosstab(df.type, df.oldbalanceDest == df.newbalanceDest)\n",
    "# '''Looking for destination accounts having pre\n",
    "# and post transaction balances equal to each other'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.crosstab(df.type, df.amount == 0, values=df.amount, aggfunc=np.mean)\n",
    "# Looking at average transaction amount by transaction type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What can we learn from our analysis through visualization?\n",
    "By looking at the below visualizations we can learn from our data the following:\n",
    "- Due to the disparity in our data the ability to zoom offered through plotly is exeremely helpful here.  At the greatest zoom many of these charts are difficult to analyze.\n",
    "- Graphics slowed my notebook\n",
    "- Though large in transaction size the fraudulent transactions were not large in number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trace = go.Histogram(x=df.oldbalanceOrig,\n",
    "                     nbinsx=10, name='Old Balance',)\n",
    "\n",
    "trace2 = go.Histogram(x=df.newbalanceOrig,\n",
    "                      name='New Balance', opacity=0.95)\n",
    "data = [trace, trace2]\n",
    "layout = go.Layout(title='Origin Account Comparison',\n",
    "                   xaxis=dict(title='Balance'),\n",
    "                   yaxis=dict(title='Frequency',))\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig)\n",
    "# Comparing balance of origin account\n",
    "# pre- and post- transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trace = go.Histogram(x=df.amount,\n",
    "                     nbinsx=10, name='Transaction Amount',)\n",
    "data = [trace]\n",
    "layout = go.Layout(title='Transaction Amount',\n",
    "                   xaxis=dict(title='Amount'),\n",
    "                   yaxis=dict(title='Frequency',))\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig)\n",
    "# Transaction Amount Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trace = go.Box(y=df.amount, name='Transaction Amount')\n",
    "data = [trace]\n",
    "py.iplot(data)\n",
    "# box plot by transaction amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trace = go.Scatter(x=df.newbalanceDest,\n",
    "                   y=df.amount, mode='markers',\n",
    "                   marker=dict(color=df.isFraud, showscale=True))\n",
    "data = [trace]\n",
    "py.iplot(data)\n",
    "# scatter plot of tranaction amount by type and colored by fraudulent or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "annotations = [dict(x=xi, y=yi,\n",
    "                    text=str(yi), xanchor='center',\n",
    "                    yanchor='bottom', showarrow=False,)\n",
    "               for yi, xi in zip(df.isFraud.value_counts(), ['0', '1'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trace = go.Bar(\n",
    "    y=df.isFraud.value_counts(),\n",
    "    x=['0', '1'],)\n",
    "layout = go.Layout(\n",
    "    annotations=annotations)\n",
    "data = [trace]\n",
    "py.iplot(dict(data=data, layout=layout))\n",
    "# bar chart transaction type count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "annotations = [dict(x=xi, y=yi, text=str(yi),\n",
    "                    xanchor='center', yanchor='bottom',\n",
    "                    showarrow=False,)\n",
    "               for yi, xi in zip(df.type.value_counts(),\n",
    "                                 ['cash_in', 'cash_out',\n",
    "                                  'debit', 'transfer', 'payment'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trace = go.Bar(y=df.type.value_counts(),\n",
    "               x=['cash_in', 'cash_out', 'debit', 'transfer', 'payment'],)\n",
    "layout = go.Layout(annotations=annotations)\n",
    "data = [trace]\n",
    "py.iplot(dict(data=data, layout=layout))\n",
    "# bar chart transaction type count\n",
    "# completes step 3 of a methodical EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4:  Aggregation of the data and exploration of the group properties at the micro level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What can we learn from our micro level analysis?\n",
    "By looking at the below visualizations and tables we can learn from our data the following:\n",
    "- There were 276 fraudulent transactions of the Cash_Out type with a mean amount of 1,587,794 in local currency.  Half of all fraudulent transactions of this type were in the amount of 407,495\n",
    "- There were 300 fraudulent transactions of the Transfer type with a mean amount of 1,484,329 in local currency.  Half of all fraudulent transactions of this type were in the amount of 463,901\n",
    "- Only 130 (47%) fruadulent transactions were below 100,000\n",
    "- New balances for the destination accounts were 0 75% of the time for the fraudulent Transfer transaction types.  curious "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.groupby(['isFraud', 'type']).describe()\n",
    "# looking at data by transaction type and fraudulent or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.groupby(['type', df.amount < 100000]).isFraud.value_counts().unstack()\n",
    "# determining fraudulent transactions over $100,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.crosstab(df.type, df.isFraud).plot.bar()\n",
    "# completes step 4 of a methodical EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is my data coupled with my intuition telling me the story is here?\n",
    "A typical fruadulent account is not frequent in nature occuring only about .1% of the all transactions.  When a fraudulent transaction ois successful however it is devistanting, draining it's victim's account balance to $0 in nealry every case.  The average fruadulent transaction amount being 1.5 million.  Of the 5 transaction types the two that are most susceptible are Cash Out and Transfer transactions.  The risk of a fraudulent Transfer transaction taking place actually increases to 1 percent.  Interestingly the ending balance on the destination accounts on Cash Out transactions seemingly represents the increase for the fruadulent funds deposited where in the case of the Transfer transactions the funds seem to disappear.  \n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
